{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First - set up the project directory structure and create functions to save the results at the end of each section.",
   "id": "3a33cb3bcf494398"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Create directory structure\n",
    "project_dir = Path('fmri_project')\n",
    "checkpoints_dir = project_dir / 'checkpoints'\n",
    "results_dir = project_dir / 'results'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for dir_path in [checkpoints_dir, results_dir]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_checkpoint(data, filename):\n",
    "    \"\"\"Save data to checkpoint file\"\"\"\n",
    "    filepath = checkpoints_dir / filename\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Checkpoint saved: {filepath}\")\n",
    "\n",
    "def load_checkpoint(filename):\n",
    "    \"\"\"Load data from checkpoint file\"\"\"\n",
    "    filepath = checkpoints_dir / filename\n",
    "    if filepath.exists():\n",
    "        with open(filepath, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    return None"
   ],
   "id": "91a3756b6f719cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create events DataFrame from the trial information in the original \"README\" file",
   "id": "ce5ac84a3677405e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Check if events DataFrame already exists\n",
    "events = load_checkpoint('events.pkl')\n",
    "\n",
    "if events is None:\n",
    "    # Create events DataFrame with timing information\n",
    "    events = pd.DataFrame({\n",
    "        'onset': [0, 60, 120, 180, 240, 300, 360, 420, 480, 540],\n",
    "        'duration': [30] * 10,\n",
    "        'emotion': ['calm', 'afraid', 'delighted', 'depressed',\n",
    "                    'excited', 'delighted', 'depressed', 'calm',\n",
    "                    'excited', 'afraid']\n",
    "    })\n",
    "\n",
    "    # Map emotions to valence categories\n",
    "    valence_mapping = {\n",
    "        'calm': 'neutral',\n",
    "        'afraid': 'negative',\n",
    "        'delighted': 'positive',\n",
    "        'depressed': 'negative',\n",
    "        'excited': 'positive'\n",
    "    }\n",
    "    events['trial_type'] = events['emotion'].map(valence_mapping)\n",
    "\n",
    "    # Save events DataFrame\n",
    "    save_checkpoint(events, 'events.pkl')\n",
    "else:\n",
    "    print(\"Loaded existing events DataFrame\")"
   ],
   "id": "f2db7d97ecb1ac21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creat Region of interest(ROI) masks",
   "id": "2ed2847b11c27013"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from nilearn import image, input_data\n",
    "from nilearn.datasets import fetch_atlas_harvard_oxford\n",
    "\n",
    "# Check if ROI masks already exist\n",
    "roi_masks = load_checkpoint('roi_masks.pkl')\n",
    "\n",
    "if roi_masks is None:\n",
    "    # Fetch Harvard-Oxford atlases\n",
    "    cortical = fetch_atlas_harvard_oxford('cort-maxprob-thr25-2mm')\n",
    "    subcortical = fetch_atlas_harvard_oxford('sub-maxprob-thr25-2mm')\n",
    "\n",
    "    # Create ROI masks\n",
    "    roi_masks = {\n",
    "        # Subcortical regions\n",
    "        'amygdala_left': image.math_img('img == 10', img=subcortical.maps),\n",
    "        'amygdala_right': image.math_img('img == 20', img=subcortical.maps),\n",
    "        'hippocampus_left': image.math_img('img == 9', img=subcortical.maps),\n",
    "        'hippocampus_right': image.math_img('img == 19', img=subcortical.maps),\n",
    "\n",
    "        # Cortical regions\n",
    "        'acc': image.math_img('img == 29', img=cortical.maps),\n",
    "        'sup_frontal_gyrus': image.math_img('img == 3', img=cortical.maps),\n",
    "        'mid_frontal_gyrus': image.math_img('img == 4', img=cortical.maps),\n",
    "    }\n",
    "\n",
    "    # Create bilateral masks\n",
    "    bilateral_pairs = [\n",
    "        ('amygdala', 'amygdala_left', 'amygdala_right'),\n",
    "        ('hippocampus', 'hippocampus_left', 'hippocampus_right'),\n",
    "    ]\n",
    "\n",
    "    # Combine bilateral pairs\n",
    "    for name, left, right in bilateral_pairs:\n",
    "        roi_masks[f'{name}_bilateral'] = image.math_img(\n",
    "            \"img1 + img2\",\n",
    "            img1=roi_masks[left],\n",
    "            img2=roi_masks[right]\n",
    "        )\n",
    "\n",
    "    # Save ROI masks\n",
    "    save_checkpoint(roi_masks, 'roi_masks.pkl')\n",
    "else:\n",
    "    print(\"Loaded existing ROI masks\")"
   ],
   "id": "b85ae3eeb9117adc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Process individual subjects and save the results",
   "id": "59fdef48d44bbc23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "\n",
    "# Check if subject results already exist\n",
    "all_subject_contrasts = load_checkpoint('subject_contrasts.pkl')\n",
    "all_subject_roi_signals = load_checkpoint('subject_roi_signals.pkl')\n",
    "\n",
    "if all_subject_contrasts is None or all_subject_roi_signals is None:\n",
    "    # Initialize lists to store results\n",
    "    n_subjects = 40\n",
    "    all_subject_contrasts = []\n",
    "    all_subject_roi_signals = []\n",
    "\n",
    "    # Process each subject\n",
    "    for subject_id in range(1, n_subjects + 1):\n",
    "        subject_id_str = f'{subject_id:02d}'\n",
    "        print(f'Processing subject {subject_id_str}...')\n",
    "\n",
    "        # Check if individual subject results exist\n",
    "        subject_results = load_checkpoint(f'subject_{subject_id_str}_results.pkl')\n",
    "\n",
    "        if subject_results is None:\n",
    "            # Load subject data\n",
    "            func_file = f'ds005700/sub-{subject_id_str}/func/sub-{subject_id_str}_task-fe_bold.nii.gz'\n",
    "            anat_file = f'ds005700/sub-{subject_id_str}/anat/sub-{subject_id_str}_T1w.nii.gz'\n",
    "\n",
    "            func_img = image.load_img(func_file)\n",
    "            anat_img = image.load_img(anat_file)\n",
    "\n",
    "            # Create and fit first-level model\n",
    "            model = FirstLevelModel(\n",
    "                t_r=2.02697,  # Time repetition from .json file\n",
    "                noise_model='ar1',\n",
    "                standardize=True,\n",
    "                hrf_model='spm',\n",
    "                drift_model='cosine'\n",
    "            )\n",
    "\n",
    "            model.fit(func_img, events)\n",
    "\n",
    "            # Define and compute contrasts\n",
    "            contrasts = {\n",
    "                'positive_vs_neutral': 'positive - neutral',\n",
    "                'negative_vs_neutral': 'negative - neutral',\n",
    "                'positive_vs_negative': 'positive - negative'\n",
    "            }\n",
    "\n",
    "            contrast_maps = {}\n",
    "            for contrast_id, contrast_def in contrasts.items():\n",
    "                contrast_maps[contrast_id] = model.compute_contrast(contrast_def)\n",
    "\n",
    "            # Extract ROI signals\n",
    "            roi_signals = {}\n",
    "            for roi_name, roi_mask in roi_masks.items():\n",
    "                masker = input_data.NiftiMasker(mask_img=roi_mask)\n",
    "                roi_signals[roi_name] = masker.fit_transform(func_img)\n",
    "\n",
    "            # Save individual subject results\n",
    "            subject_results = {'contrasts': contrast_maps, 'roi_signals': roi_signals}\n",
    "            save_checkpoint(subject_results, f'subject_{subject_id_str}_results.pkl')\n",
    "        else:\n",
    "            print(f\"Loaded existing results for subject {subject_id_str}\")\n",
    "            contrast_maps = subject_results['contrasts']\n",
    "            roi_signals = subject_results['roi_signals']\n",
    "\n",
    "        all_subject_contrasts.append(contrast_maps)\n",
    "        all_subject_roi_signals.append(roi_signals)\n",
    "\n",
    "    # Save all subject results\n",
    "    save_checkpoint(all_subject_contrasts, 'subject_contrasts.pkl')\n",
    "    save_checkpoint(all_subject_roi_signals, 'subject_roi_signals.pkl')\n",
    "else:\n",
    "    print(\"Loaded existing subject results\")"
   ],
   "id": "81199fc810832d08",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "second-level group analysis",
   "id": "f428863c54a4540b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "from nilearn import plotting, image\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Check if group results already exist\n",
    "group_results = load_checkpoint('group_results.pkl')\n",
    "\n",
    "if group_results is None:\n",
    "    # Create design matrix for second-level analysis\n",
    "    n_subjects = 40\n",
    "    design_matrix = pd.DataFrame({\n",
    "        'intercept': np.ones(n_subjects),\n",
    "    })\n",
    "\n",
    "    # Initialize second-level model with explicit parameters\n",
    "    second_level_model = SecondLevelModel(\n",
    "        smoothing_fwhm=8.0,  # Add explicit smoothing\n",
    "        n_jobs=1,  # Ensure single job for stability\n",
    "        memory=None,  # Don't cache computations\n",
    "        verbose=0  # Reduce verbosity\n",
    "    )\n",
    "\n",
    "    # Define contrasts to analyze\n",
    "    contrasts_to_analyze = [\n",
    "        'positive_vs_neutral',\n",
    "        'negative_vs_neutral',\n",
    "        'positive_vs_negative'\n",
    "    ]\n",
    "\n",
    "    # Initialize dictionary to store results\n",
    "    group_results = {}\n",
    "\n",
    "    # Process each contrast\n",
    "    for contrast_name in contrasts_to_analyze:\n",
    "        print(f\"Running group analysis for {contrast_name}...\")\n",
    "\n",
    "        # Extract and preprocess contrast maps for all subjects\n",
    "        contrast_maps_list = []\n",
    "\n",
    "        # Get the first map to use as reference\n",
    "        first_map = all_subject_contrasts[0][contrast_name]\n",
    "        reference_affine = first_map.affine\n",
    "        reference_shape = first_map.shape[:3]  # Exclude time dimension if present\n",
    "\n",
    "        # Process each subject's contrast map\n",
    "        for subject_contrasts in all_subject_contrasts:\n",
    "            contrast_img = subject_contrasts[contrast_name]\n",
    "\n",
    "            # Ensure 3D\n",
    "            if len(contrast_img.shape) == 4:\n",
    "                contrast_img = image.index_img(contrast_img, 0)\n",
    "\n",
    "            # Resample to match reference with explicit parameters\n",
    "            resampled_img = image.resample_img(\n",
    "                contrast_img,\n",
    "                target_affine=reference_affine,\n",
    "                target_shape=reference_shape,\n",
    "                interpolation='continuous',\n",
    "                force_resample=True,\n",
    "                copy_header=True,\n",
    "                clip=True\n",
    "            )\n",
    "\n",
    "            contrast_maps_list.append(resampled_img)\n",
    "\n",
    "        try:\n",
    "            # Fit the second-level model\n",
    "            second_level_model.fit(contrast_maps_list, design_matrix=design_matrix)\n",
    "\n",
    "            # Compute the group-level contrast\n",
    "            z_map = second_level_model.compute_contrast(\n",
    "                output_type='z_score',\n",
    "                second_level_stat_type='t'  # Explicitly specify t-test\n",
    "            )\n",
    "            p_map = second_level_model.compute_contrast(\n",
    "                output_type='p_value',\n",
    "                second_level_stat_type='t'\n",
    "            )\n",
    "\n",
    "            # Store results\n",
    "            group_results[contrast_name] = (z_map, p_map)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing contrast {contrast_name}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # Save group results\n",
    "    save_checkpoint(group_results, 'group_results.pkl')\n",
    "else:\n",
    "    print(\"Loaded existing group results\")"
   ],
   "id": "139e315b5e9bf409",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Plot the contrasts results",
   "id": "61a3fc50f52306a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting parameters\n",
    "z_threshold = 3.1  # Corresponds to p < 0.001\n",
    "p_val = norm.sf(z_threshold)  # Convert Z-score to p-value\n",
    "print(f\"Z-score threshold {z_threshold} corresponds to p-value < {p_val:.3e}\")\n",
    "\n",
    "# Plot results for each contrast\n",
    "for contrast_name, (z_map, p_map) in group_results.items():\n",
    "    print(f\"Plotting results for {contrast_name}...\")\n",
    "\n",
    "    # Create figure with multiple views\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Plot sagittal, coronal, and axial views with statistical threshold\n",
    "    display = plotting.plot_stat_map(\n",
    "        z_map,\n",
    "        threshold=z_threshold,  # Apply threshold only during visualization\n",
    "        display_mode='ortho',\n",
    "        title=f'Group-level {contrast_name}\\n'\n",
    "              f'(threshold: z>{z_threshold}, p<{p_val:.3e})',\n",
    "        figure=fig\n",
    "    )\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(f'results/group_analysis_{contrast_name}(Z scores).png',\n",
    "                dpi=300,\n",
    "                bbox_inches='tight')\n",
    "    plt.close()"
   ],
   "id": "a2775d359a9dc9bb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
