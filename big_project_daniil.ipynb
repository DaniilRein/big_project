{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nilearn import image, input_data, plotting\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "from nilearn.plotting import plot_stat_map\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from nilearn.datasets import fetch_atlas_harvard_oxford"
   ],
   "id": "56f273aa1ece8a4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First We Setup Project Directory Structure",
   "id": "3a33cb3bcf494398"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create directory structure\n",
    "project_dir = Path('fmri_project')\n",
    "checkpoints_dir = project_dir / 'checkpoints'\n",
    "results_dir = project_dir / 'results'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for dir_path in [checkpoints_dir, results_dir]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_checkpoint(data, filename):\n",
    "    \"\"\"Save data to checkpoint file\"\"\"\n",
    "    filepath = checkpoints_dir / filename\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Checkpoint saved: {filepath}\")\n",
    "\n",
    "def load_checkpoint(filename):\n",
    "    \"\"\"Load data from checkpoint file\"\"\"\n",
    "    filepath = checkpoints_dir / filename\n",
    "    if filepath.exists():\n",
    "        with open(filepath, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    return None"
   ],
   "id": "91a3756b6f719cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create events DataFrame from the trial information in the original \"README\" file",
   "id": "ce5ac84a3677405e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check if events DataFrame already exists\n",
    "events = load_checkpoint('events.pkl')\n",
    "\n",
    "if events is None:\n",
    "    # Create events DataFrame with timing information\n",
    "    events = pd.DataFrame({\n",
    "        'onset': [0, 60, 120, 180, 240, 300, 360, 420, 480, 540],\n",
    "        'duration': [30] * 10,\n",
    "        'emotion': ['calm', 'afraid', 'delighted', 'depressed',\n",
    "                    'excited', 'delighted', 'depressed', 'calm',\n",
    "                    'excited', 'afraid']\n",
    "    })\n",
    "\n",
    "    # Map emotions to valence categories\n",
    "    valence_mapping = {\n",
    "        'calm': 'neutral',\n",
    "        'afraid': 'negative',\n",
    "        'delighted': 'positive',\n",
    "        'depressed': 'negative',\n",
    "        'excited': 'positive'\n",
    "    }\n",
    "    events['trial_type'] = events['emotion'].map(valence_mapping)\n",
    "\n",
    "    # Save events DataFrame\n",
    "    save_checkpoint(events, 'events.pkl')\n",
    "else:\n",
    "    print(\"Loaded existing events DataFrame\")"
   ],
   "id": "f2db7d97ecb1ac21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creat Region of interest(ROI) masks",
   "id": "2ed2847b11c27013"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check if ROI masks already exist\n",
    "roi_masks = load_checkpoint('roi_masks.pkl')\n",
    "\n",
    "if roi_masks is None:\n",
    "    # Fetch Harvard-Oxford atlases\n",
    "    cortical = fetch_atlas_harvard_oxford('cort-maxprob-thr25-2mm')\n",
    "    subcortical = fetch_atlas_harvard_oxford('sub-maxprob-thr25-2mm')\n",
    "\n",
    "    # Create ROI masks\n",
    "    roi_masks = {\n",
    "        # Subcortical regions\n",
    "        'amygdala_left': image.math_img('img == 10', img=subcortical.maps),\n",
    "        'amygdala_right': image.math_img('img == 20', img=subcortical.maps),\n",
    "        'hippocampus_left': image.math_img('img == 9', img=subcortical.maps),\n",
    "        'hippocampus_right': image.math_img('img == 19', img=subcortical.maps),\n",
    "\n",
    "        # Cortical regions\n",
    "        'acc': image.math_img('img == 29', img=cortical.maps),\n",
    "        'sup_frontal_gyrus': image.math_img('img == 3', img=cortical.maps),\n",
    "        'mid_frontal_gyrus': image.math_img('img == 4', img=cortical.maps),\n",
    "    }\n",
    "\n",
    "    # Create bilateral masks\n",
    "    bilateral_pairs = [\n",
    "        ('amygdala', 'amygdala_left', 'amygdala_right'),\n",
    "        ('hippocampus', 'hippocampus_left', 'hippocampus_right'),\n",
    "    ]\n",
    "\n",
    "    # Combine bilateral pairs\n",
    "    for name, left, right in bilateral_pairs:\n",
    "        roi_masks[f'{name}_bilateral'] = image.math_img(\n",
    "            \"img1 + img2\",\n",
    "            img1=roi_masks[left],\n",
    "            img2=roi_masks[right]\n",
    "        )\n",
    "\n",
    "    # Save ROI masks\n",
    "    save_checkpoint(roi_masks, 'roi_masks.pkl')\n",
    "else:\n",
    "    print(\"Loaded existing ROI masks\")"
   ],
   "id": "b85ae3eeb9117adc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Process individual subjects and save the results",
   "id": "59fdef48d44bbc23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check if subject results already exist\n",
    "all_subject_contrasts = load_checkpoint('subject_contrasts.pkl')\n",
    "all_subject_roi_signals = load_checkpoint('subject_roi_signals.pkl')\n",
    "\n",
    "if all_subject_contrasts is None or all_subject_roi_signals is None:\n",
    "    # Initialize lists to store results\n",
    "    n_subjects = 40\n",
    "    all_subject_contrasts = []\n",
    "    all_subject_roi_signals = []\n",
    "\n",
    "    # Process each subject\n",
    "    for subject_id in range(1, n_subjects + 1):\n",
    "        subject_id_str = f'{subject_id:02d}'\n",
    "        print(f'Processing subject {subject_id_str}...')\n",
    "\n",
    "        # Check if individual subject results exist\n",
    "        subject_results = load_checkpoint(f'subject_{subject_id_str}_results.pkl')\n",
    "\n",
    "        if subject_results is None:\n",
    "            # Load subject data\n",
    "            func_file = f'ds005700/sub-{subject_id_str}/func/sub-{subject_id_str}_task-fe_bold.nii.gz'\n",
    "            anat_file = f'ds005700/sub-{subject_id_str}/anat/sub-{subject_id_str}_T1w.nii.gz'\n",
    "\n",
    "            func_img = image.load_img(func_file)\n",
    "            anat_img = image.load_img(anat_file)\n",
    "\n",
    "            # Create and fit first-level model\n",
    "            model = FirstLevelModel(\n",
    "                t_r=2.02697,  # Time repetition from .json file\n",
    "                noise_model='ar1',\n",
    "                standardize=True,\n",
    "                hrf_model='spm',\n",
    "                drift_model='cosine'\n",
    "            )\n",
    "\n",
    "            model.fit(func_img, events)\n",
    "\n",
    "            # Define and compute contrasts\n",
    "            contrasts = {\n",
    "                'positive_vs_neutral': 'positive - neutral',\n",
    "                'negative_vs_neutral': 'negative - neutral',\n",
    "                'positive_vs_negative': 'positive - negative'\n",
    "            }\n",
    "\n",
    "            contrast_maps = {}\n",
    "            for contrast_id, contrast_def in contrasts.items():\n",
    "                contrast_maps[contrast_id] = model.compute_contrast(contrast_def)\n",
    "\n",
    "            # Extract ROI signals\n",
    "            roi_signals = {}\n",
    "            for roi_name, roi_mask in roi_masks.items():\n",
    "                masker = input_data.NiftiMasker(mask_img=roi_mask)\n",
    "                roi_signals[roi_name] = masker.fit_transform(func_img)\n",
    "\n",
    "            # Save individual subject results\n",
    "            subject_results = {'contrasts': contrast_maps, 'roi_signals': roi_signals}\n",
    "            save_checkpoint(subject_results, f'subject_{subject_id_str}_results.pkl')\n",
    "        else:\n",
    "            print(f\"Loaded existing results for subject {subject_id_str}\")\n",
    "            contrast_maps = subject_results['contrasts']\n",
    "            roi_signals = subject_results['roi_signals']\n",
    "\n",
    "        all_subject_contrasts.append(contrast_maps)\n",
    "        all_subject_roi_signals.append(roi_signals)\n",
    "\n",
    "    # Save all subject results\n",
    "    save_checkpoint(all_subject_contrasts, 'subject_contrasts.pkl')\n",
    "    save_checkpoint(all_subject_roi_signals, 'subject_roi_signals.pkl')\n",
    "else:\n",
    "    print(\"Loaded existing subject results\")\n"
   ],
   "id": "81199fc810832d08",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create the design matrix for my experiment and perform the second-level group analysis",
   "id": "f428863c54a4540b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T16:16:17.314345Z",
     "start_time": "2025-01-12T16:16:09.403342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting\n",
    "\n",
    "# Create design matrix for second-level analysis\n",
    "n_subjects = 40\n",
    "design_matrix = pd.DataFrame({\n",
    "    'intercept': np.ones(n_subjects),\n",
    "})\n",
    "\n",
    "# Initialize second-level model\n",
    "second_level_model = SecondLevelModel()\n",
    "\n",
    "# Function to perform group analysis for a specific contrast\n",
    "def run_group_analysis(contrast_maps, contrast_name, design_matrix):\n",
    "    \"\"\"\n",
    "    Perform second-level analysis for a specific contrast.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    contrast_maps : list\n",
    "        List of first-level contrast maps for all subjects\n",
    "    contrast_name : str\n",
    "        Name of the contrast being analyzed\n",
    "    design_matrix : pd.DataFrame\n",
    "        Design matrix for the second-level analysis\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (z_map, p_map) containing the statistical maps\n",
    "    \"\"\"\n",
    "    # Extract the specific contrast maps for all subjects\n",
    "    contrast_maps_list = [subject_contrasts[contrast_name]\n",
    "                         for subject_contrasts in contrast_maps]\n",
    "\n",
    "    # Fit the second-level model\n",
    "    second_level_model.fit(contrast_maps_list, design_matrix=design_matrix)\n",
    "\n",
    "    # Compute the group-level contrast\n",
    "    # Using intercept as we're interested in the group mean effect\n",
    "    z_map = second_level_model.compute_contrast(output_type='z_score')\n",
    "    p_map = second_level_model.compute_contrast(output_type='p_value')\n",
    "\n",
    "    return z_map, p_map\n",
    "\n",
    "# Function to visualize results\n",
    "def plot_group_results(z_map, p_map, contrast_name, threshold=3.1):\n",
    "    \"\"\"\n",
    "    Create visualization of the group-level results.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    z_map : Nifti1Image\n",
    "        Z-score map from the group analysis\n",
    "    p_map : Nifti1Image\n",
    "        P-value map from the group analysis\n",
    "    contrast_name : str\n",
    "        Name of the contrast for plotting\n",
    "    threshold : float\n",
    "        Z-score threshold for visualization (default=3.1, corresponding to p<0.001)\n",
    "    \"\"\"\n",
    "    # Create figure with multiple views\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Plot sagittal, coronal, and axial views\n",
    "    display = plotting.plot_stat_map(\n",
    "        z_map,\n",
    "        threshold=threshold,\n",
    "        display_mode='ortho',\n",
    "        cut_coords=[0, 0, 0],\n",
    "        title=f'Group-level {contrast_name}\\n(threshold: z>{threshold})',\n",
    "        figure=fig\n",
    "    )\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(f'results/group_analysis_{contrast_name}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Create glass brain view\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    plotting.plot_glass_brain(\n",
    "        z_map,\n",
    "        threshold=threshold,\n",
    "        title=f'Glass brain view: {contrast_name}',\n",
    "        figure=fig\n",
    "    )\n",
    "    plt.savefig(f'results/glass_brain_{contrast_name}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Run group analysis for each contrast\n",
    "contrasts_to_analyze = [\n",
    "    'positive_vs_neutral',\n",
    "    'negative_vs_neutral',\n",
    "    'positive_vs_negative'\n",
    "]\n",
    "\n",
    "group_results = {}\n",
    "for contrast_name in contrasts_to_analyze:\n",
    "    print(f\"Running group analysis for {contrast_name}...\")\n",
    "    z_map, p_map = run_group_analysis(all_subject_contrasts, contrast_name, design_matrix)\n",
    "    group_results[contrast_name] = (z_map, p_map)\n",
    "\n",
    "    # Visualize results\n",
    "    plot_group_results(z_map, p_map, contrast_name)\n",
    "\n",
    "    # Save the statistical maps\n",
    "    z_map.to_filename(f'results/group_zmap_{contrast_name}.nii.gz')\n",
    "    p_map.to_filename(f'results/group_pmap_{contrast_name}.nii.gz')\n",
    "\n",
    "# Save group results\n",
    "save_checkpoint(group_results, 'group_results.pkl')\n"
   ],
   "id": "e00e3900ae100b40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running group analysis for positive_vs_neutral...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Field of view of image #1 is different from reference FOV.\nReference affine:\narray([[-1.79687083e+00,  3.46259400e-03, -3.91001394e-03,\n         1.16352135e+02],\n       [ 3.46657564e-03,  1.79686713e+00, -9.08396207e-03,\n        -1.19556023e+02],\n       [-1.74858025e-03,  4.08406509e-03,  3.99998784e+00,\n        -6.26113434e+01],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         1.00000000e+00]])\nImage affine:\narray([[-1.78331065e+00,  8.33820552e-02,  4.54090238e-01,\n         9.81907120e+01],\n       [ 8.01479965e-02,  1.79478395e+00, -7.33785704e-02,\n        -1.16520119e+02],\n       [ 2.05278084e-01,  2.36155912e-02,  3.97346401e+00,\n        -1.00045982e+02],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         1.00000000e+00]])\nReference shape:\n(128, 128, 36)\nImage shape:\n(128, 128, 36, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 103\u001B[0m\n\u001B[1;32m    101\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m contrast_name \u001B[38;5;129;01min\u001B[39;00m contrasts_to_analyze:\n\u001B[1;32m    102\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRunning group analysis for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcontrast_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 103\u001B[0m     z_map, p_map \u001B[38;5;241m=\u001B[39m \u001B[43mrun_group_analysis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mall_subject_contrasts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontrast_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdesign_matrix\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    104\u001B[0m     group_results[contrast_name] \u001B[38;5;241m=\u001B[39m (z_map, p_map)\n\u001B[1;32m    106\u001B[0m     \u001B[38;5;66;03m# Visualize results\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[23], line 44\u001B[0m, in \u001B[0;36mrun_group_analysis\u001B[0;34m(contrast_maps, contrast_name, design_matrix)\u001B[0m\n\u001B[1;32m     40\u001B[0m second_level_model\u001B[38;5;241m.\u001B[39mfit(contrast_maps_list, design_matrix\u001B[38;5;241m=\u001B[39mdesign_matrix)\n\u001B[1;32m     42\u001B[0m \u001B[38;5;66;03m# Compute the group-level contrast\u001B[39;00m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;66;03m# Using intercept as we're interested in the group mean effect\u001B[39;00m\n\u001B[0;32m---> 44\u001B[0m z_map \u001B[38;5;241m=\u001B[39m \u001B[43msecond_level_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_contrast\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mz_score\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     45\u001B[0m p_map \u001B[38;5;241m=\u001B[39m second_level_model\u001B[38;5;241m.\u001B[39mcompute_contrast(output_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mp_value\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m z_map, p_map\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/nilearn/glm/second_level/second_level.py:772\u001B[0m, in \u001B[0;36mSecondLevelModel.compute_contrast\u001B[0;34m(self, second_level_contrast, first_level_contrast, second_level_stat_type, output_type)\u001B[0m\n\u001B[1;32m    769\u001B[0m _check_n_rows_desmat_vs_n_effect_maps(effect_maps, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdesign_matrix_)\n\u001B[1;32m    771\u001B[0m \u001B[38;5;66;03m# Fit an Ordinary Least Squares regression for parametric statistics\u001B[39;00m\n\u001B[0;32m--> 772\u001B[0m Y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmasker_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43meffect_maps\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    773\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmemory:\n\u001B[1;32m    774\u001B[0m     mem_glm \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmemory\u001B[38;5;241m.\u001B[39mcache(run_glm, ignore\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn_jobs\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/_set_output.py:316\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[0;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[1;32m    314\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[1;32m    315\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 316\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    317\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    318\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[1;32m    319\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    320\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    321\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[1;32m    322\u001B[0m         )\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/nilearn/maskers/base_masker.py:282\u001B[0m, in \u001B[0;36mBaseMasker.transform\u001B[0;34m(self, imgs, confounds, sample_mask)\u001B[0m\n\u001B[1;32m    279\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_fitted()\n\u001B[1;32m    281\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m confounds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhigh_variance_confounds:\n\u001B[0;32m--> 282\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform_single_imgs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[43m        \u001B[49m\u001B[43mimgs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfounds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_mask\u001B[49m\n\u001B[1;32m    284\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    286\u001B[0m \u001B[38;5;66;03m# Compute high variance confounds if requested\u001B[39;00m\n\u001B[1;32m    287\u001B[0m all_confounds \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/nilearn/maskers/nifti_masker.py:607\u001B[0m, in \u001B[0;36mNiftiMasker.transform_single_imgs\u001B[0;34m(self, imgs, confounds, sample_mask, copy)\u001B[0m\n\u001B[1;32m    594\u001B[0m params \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mclass_inspect\u001B[38;5;241m.\u001B[39mget_params(\n\u001B[1;32m    595\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m,\n\u001B[1;32m    596\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    603\u001B[0m     ],\n\u001B[1;32m    604\u001B[0m )\n\u001B[1;32m    605\u001B[0m params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclean_kwargs\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclean_kwargs\n\u001B[0;32m--> 607\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    608\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_filter_and_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    609\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\n\u001B[1;32m    610\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mverbose\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    611\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    612\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_level\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    613\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcopy\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    614\u001B[0m \u001B[43m    \u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    615\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshelve\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_shelving\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    616\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    617\u001B[0m \u001B[43m    \u001B[49m\u001B[43mimgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    618\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmask_img_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    619\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    620\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_level\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmemory_level\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    621\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmemory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    622\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    623\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    624\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    625\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    626\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    627\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/joblib/memory.py:312\u001B[0m, in \u001B[0;36mNotMemorizedFunc.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 312\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/nilearn/maskers/nifti_masker.py:96\u001B[0m, in \u001B[0;36m_filter_and_mask\u001B[0;34m(imgs, mask_img_, parameters, memory_level, memory, verbose, confounds, sample_mask, copy, dtype)\u001B[0m\n\u001B[1;32m     92\u001B[0m     memory \u001B[38;5;241m=\u001B[39m Memory(location\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m     93\u001B[0m \u001B[38;5;66;03m# Convert input to niimg to check shape.\u001B[39;00m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;66;03m# This must be repeated after the shape check because check_niimg will\u001B[39;00m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;66;03m# coerce 5D data to 4D, which we don't want.\u001B[39;00m\n\u001B[0;32m---> 96\u001B[0m temp_imgs \u001B[38;5;241m=\u001B[39m \u001B[43m_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck_niimg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimgs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;66;03m# Raise warning if a 3D niimg is provided.\u001B[39;00m\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m temp_imgs\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/nilearn/_utils/niimg_conversions.py:312\u001B[0m, in \u001B[0;36mcheck_niimg\u001B[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001B[0m\n\u001B[1;32m    308\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m return_iterator:\n\u001B[1;32m    309\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m iter_check_niimg(\n\u001B[1;32m    310\u001B[0m             niimg, ensure_ndim\u001B[38;5;241m=\u001B[39mensure_ndim, dtype\u001B[38;5;241m=\u001B[39mdtype\n\u001B[1;32m    311\u001B[0m         )\n\u001B[0;32m--> 312\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mni\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcat_imgs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    313\u001B[0m \u001B[43m        \u001B[49m\u001B[43mniimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mensure_ndim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_ndim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\n\u001B[1;32m    314\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[38;5;66;03m# Otherwise, it should be a filename or a SpatialImage, we load it\u001B[39;00m\n\u001B[1;32m    317\u001B[0m niimg \u001B[38;5;241m=\u001B[39m load_niimg(niimg, dtype\u001B[38;5;241m=\u001B[39mdtype)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/nilearn/image/image.py:1580\u001B[0m, in \u001B[0;36mconcat_imgs\u001B[0;34m(niimgs, dtype, ensure_ndim, memory, memory_level, auto_resample, verbose)\u001B[0m\n\u001B[1;32m   1578\u001B[0m data \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray((\u001B[38;5;241m*\u001B[39mtarget_shape, \u001B[38;5;28msum\u001B[39m(lengths)), order\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mF\u001B[39m\u001B[38;5;124m\"\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[1;32m   1579\u001B[0m cur_4d_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m-> 1580\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mniimg\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1581\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1582\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlengths\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1583\u001B[0m \u001B[43m        \u001B[49m\u001B[43miter_check_niimg\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1584\u001B[0m \u001B[43m            \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1585\u001B[0m \u001B[43m            \u001B[49m\u001B[43matleast_4d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1586\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtarget_fov\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_fov\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1587\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmemory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmemory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1588\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmemory_level\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmemory_level\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1589\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1590\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1591\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1592\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnii_str\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1593\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mimage \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mniimg\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mniimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mimage #\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mindex\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[1;32m   1594\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1595\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlogger\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mConcatenating \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mindex\u001B[49m\u001B[38;5;250;43m \u001B[39;49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;250;43m \u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m: \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mnii_str\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/nilearn/_utils/niimg_conversions.py:159\u001B[0m, in \u001B[0;36miter_check_niimg\u001B[0;34m(niimgs, ensure_ndim, atleast_4d, target_fov, dtype, memory, memory_level)\u001B[0m\n\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _check_fov(niimg, ref_fov[\u001B[38;5;241m0\u001B[39m], ref_fov[\u001B[38;5;241m1\u001B[39m]):\n\u001B[1;32m    158\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m target_fov \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 159\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    160\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mField of view of image #\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is different from \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    161\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreference FOV.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    162\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReference affine:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mref_fov[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    163\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImage affine:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mniimg\u001B[38;5;241m.\u001B[39maffine\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    164\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReference shape:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mref_fov[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    165\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImage shape:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mniimg\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    166\u001B[0m         )\n\u001B[1;32m    167\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnilearn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m image  \u001B[38;5;66;03m# we avoid a circular import\u001B[39;00m\n\u001B[1;32m    169\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m resample_to_first_img:\n",
      "\u001B[0;31mValueError\u001B[0m: Field of view of image #1 is different from reference FOV.\nReference affine:\narray([[-1.79687083e+00,  3.46259400e-03, -3.91001394e-03,\n         1.16352135e+02],\n       [ 3.46657564e-03,  1.79686713e+00, -9.08396207e-03,\n        -1.19556023e+02],\n       [-1.74858025e-03,  4.08406509e-03,  3.99998784e+00,\n        -6.26113434e+01],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         1.00000000e+00]])\nImage affine:\narray([[-1.78331065e+00,  8.33820552e-02,  4.54090238e-01,\n         9.81907120e+01],\n       [ 8.01479965e-02,  1.79478395e+00, -7.33785704e-02,\n        -1.16520119e+02],\n       [ 2.05278084e-01,  2.36155912e-02,  3.97346401e+00,\n        -1.00045982e+02],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         1.00000000e+00]])\nReference shape:\n(128, 128, 36)\nImage shape:\n(128, 128, 36, 1)\n"
     ]
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
