{
 "cells": [
  {
   "cell_type": "code",
   "id": "30881c5194c59db5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T10:11:25.000864Z",
     "start_time": "2025-01-15T10:11:24.981547Z"
    }
   },
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Create directory structure\n",
    "project_dir = Path('fmri_project')\n",
    "checkpoints_dir = project_dir / 'checkpoints'\n",
    "results_dir = project_dir / 'results'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for dir_path in [checkpoints_dir, results_dir]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_checkpoint(data, filename):\n",
    "    \"\"\"Save data to checkpoint file\"\"\"\n",
    "    filepath = checkpoints_dir / filename\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Checkpoint saved: {filepath}\")\n",
    "\n",
    "\n",
    "def load_checkpoint(filename):\n",
    "    \"\"\"Load data from checkpoint file\"\"\"\n",
    "    filepath = checkpoints_dir / filename\n",
    "    if filepath.exists():\n",
    "        with open(filepath, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    return None"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T10:11:25.030524Z",
     "start_time": "2025-01-15T10:11:25.011973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Check if events DataFrame already exists\n",
    "events = load_checkpoint('events.pkl')\n",
    "\n",
    "if events is None:\n",
    "    # Create events DataFrame with timing information\n",
    "    events = pd.DataFrame({\n",
    "        'onset': [0, 60, 120, 180, 240, 300, 360, 420, 480, 540],\n",
    "        'duration': [30] * 10,\n",
    "        'trial_type': ['neutral', 'negative', 'positive', 'negative',\n",
    "                      'positive', 'positive', 'negative', 'neutral',\n",
    "                      'positive', 'negative']\n",
    "    })\n",
    "\n",
    "    # Save events DataFrame\n",
    "    save_checkpoint(events, 'events.pkl')\n",
    "else:\n",
    "    print(\"Loaded existing events DataFrame\")\n",
    "# if events is None:\n",
    "#     # Create events DataFrame with timing information\n",
    "#     events = pd.DataFrame({\n",
    "#         'onset': [0, 60, 120, 180, 240, 300, 360, 420, 480, 540],\n",
    "#         'duration': [30] * 10,\n",
    "#         'emotion': ['calm', 'afraid', 'delighted', 'depressed',\n",
    "#                     'excited', 'delighted', 'depressed', 'calm',\n",
    "#                     'excited', 'afraid']\n",
    "#     })\n",
    "#\n",
    "#     # Map emotions to valence categories\n",
    "#     valence_mapping = {\n",
    "#         'calm': 'neutral',\n",
    "#         'afraid': 'negative',\n",
    "#         'delighted': 'positive',\n",
    "#         'depressed': 'negative',\n",
    "#         'excited': 'positive'\n",
    "#     }\n",
    "#     events['trial_type'] = events['emotion'].map(valence_mapping)\n",
    "#\n",
    "#     # Save events DataFrame\n",
    "#     save_checkpoint(events, 'events.pkl')\n",
    "# else:\n",
    "#     print(\"Loaded existing events DataFrame\")"
   ],
   "id": "ccde05bd00c3f203",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: fmri_project/checkpoints/events.pkl\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T10:11:25.682419Z",
     "start_time": "2025-01-15T10:11:25.056871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nilearn import image\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "\n",
    "# Check if subject results already exist\n",
    "all_subject_contrasts = load_checkpoint('subject_contrasts.pkl')\n",
    "\n",
    "if all_subject_contrasts is None:\n",
    "    # Initialize lists to store results\n",
    "    n_subjects = 40\n",
    "    all_subject_contrasts = []\n",
    "\n",
    "    # Process each subject\n",
    "    for subject_id in range(1, n_subjects + 1):\n",
    "        subject_id_str = f'{subject_id:02d}'\n",
    "        print(f'Processing subject {subject_id_str}...')\n",
    "\n",
    "        # Check if individual subject results exist\n",
    "        subject_results = load_checkpoint(f'subject_{subject_id_str}_results.pkl')\n",
    "\n",
    "        if subject_results is None:\n",
    "            # Load subject data\n",
    "            func_file = f'ds005700/sub-{subject_id_str}/func/sub-{subject_id_str}_task-fe_bold.nii.gz'\n",
    "            anat_file = f'ds005700/sub-{subject_id_str}/anat/sub-{subject_id_str}_T1w.nii.gz'\n",
    "\n",
    "            func_img = image.load_img(func_file)\n",
    "            anat_img = image.load_img(anat_file)\n",
    "\n",
    "            # Create and fit first-level model\n",
    "            model = FirstLevelModel(\n",
    "                t_r=2.02697,  # Time repetition from .json file\n",
    "                noise_model='ar1',\n",
    "                standardize=True,\n",
    "                hrf_model='spm',\n",
    "                drift_model='cosine'\n",
    "            )\n",
    "\n",
    "            model.fit(func_img, events)\n",
    "\n",
    "            # Define and compute contrasts\n",
    "            contrasts = {\n",
    "                'positive_vs_neutral': 'positive - neutral',\n",
    "                'negative_vs_neutral': 'negative - neutral',\n",
    "                'positive_vs_negative': 'positive - negative'\n",
    "            }\n",
    "\n",
    "            contrast_maps = {}\n",
    "            for contrast_id, contrast_def in contrasts.items():\n",
    "                contrast_maps[contrast_id] = model.compute_contrast(contrast_def)\n",
    "\n",
    "            # Save individual subject results\n",
    "            subject_results = {'contrasts': contrast_maps}\n",
    "            save_checkpoint(subject_results, f'subject_{subject_id_str}_results.pkl')\n",
    "        else:\n",
    "            print(f\"Loaded existing results for subject {subject_id_str}\")\n",
    "            contrast_maps = subject_results['contrasts']\n",
    "\n",
    "        all_subject_contrasts.append(contrast_maps)\n",
    "\n",
    "    # Save all subject results\n",
    "    save_checkpoint(all_subject_contrasts, 'subject_contrasts.pkl')\n",
    "else:\n",
    "    print(\"Loaded existing subject results\")"
   ],
   "id": "84bf839bb8ff0bcf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject 01...\n",
      "Loaded existing results for subject 01\n",
      "Processing subject 02...\n",
      "Loaded existing results for subject 02\n",
      "Processing subject 03...\n",
      "Loaded existing results for subject 03\n",
      "Processing subject 04...\n",
      "Loaded existing results for subject 04\n",
      "Processing subject 05...\n",
      "Loaded existing results for subject 05\n",
      "Processing subject 06...\n",
      "Loaded existing results for subject 06\n",
      "Processing subject 07...\n",
      "Loaded existing results for subject 07\n",
      "Processing subject 08...\n",
      "Loaded existing results for subject 08\n",
      "Processing subject 09...\n",
      "Loaded existing results for subject 09\n",
      "Processing subject 10...\n",
      "Loaded existing results for subject 10\n",
      "Processing subject 11...\n",
      "Loaded existing results for subject 11\n",
      "Processing subject 12...\n",
      "Loaded existing results for subject 12\n",
      "Processing subject 13...\n",
      "Loaded existing results for subject 13\n",
      "Processing subject 14...\n",
      "Loaded existing results for subject 14\n",
      "Processing subject 15...\n",
      "Loaded existing results for subject 15\n",
      "Processing subject 16...\n",
      "Loaded existing results for subject 16\n",
      "Processing subject 17...\n",
      "Loaded existing results for subject 17\n",
      "Processing subject 18...\n",
      "Loaded existing results for subject 18\n",
      "Processing subject 19...\n",
      "Loaded existing results for subject 19\n",
      "Processing subject 20...\n",
      "Loaded existing results for subject 20\n",
      "Processing subject 21...\n",
      "Loaded existing results for subject 21\n",
      "Processing subject 22...\n",
      "Loaded existing results for subject 22\n",
      "Processing subject 23...\n",
      "Loaded existing results for subject 23\n",
      "Processing subject 24...\n",
      "Loaded existing results for subject 24\n",
      "Processing subject 25...\n",
      "Loaded existing results for subject 25\n",
      "Processing subject 26...\n",
      "Loaded existing results for subject 26\n",
      "Processing subject 27...\n",
      "Loaded existing results for subject 27\n",
      "Processing subject 28...\n",
      "Loaded existing results for subject 28\n",
      "Processing subject 29...\n",
      "Loaded existing results for subject 29\n",
      "Processing subject 30...\n",
      "Loaded existing results for subject 30\n",
      "Processing subject 31...\n",
      "Loaded existing results for subject 31\n",
      "Processing subject 32...\n",
      "Loaded existing results for subject 32\n",
      "Processing subject 33...\n",
      "Loaded existing results for subject 33\n",
      "Processing subject 34...\n",
      "Loaded existing results for subject 34\n",
      "Processing subject 35...\n",
      "Loaded existing results for subject 35\n",
      "Processing subject 36...\n",
      "Loaded existing results for subject 36\n",
      "Processing subject 37...\n",
      "Loaded existing results for subject 37\n",
      "Processing subject 38...\n",
      "Loaded existing results for subject 38\n",
      "Processing subject 39...\n",
      "Loaded existing results for subject 39\n",
      "Processing subject 40...\n",
      "Loaded existing results for subject 40\n",
      "Checkpoint saved: fmri_project/checkpoints/subject_contrasts.pkl\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T10:11:55.644733Z",
     "start_time": "2025-01-15T10:11:25.707945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "from nilearn import plotting, image\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Check if group results already exist\n",
    "group_results = load_checkpoint('group_results.pkl')\n",
    "\n",
    "if group_results is None:\n",
    "    # Create design matrix for second-level analysis\n",
    "    n_subjects = 40\n",
    "    design_matrix = pd.DataFrame({\n",
    "        'intercept': np.ones(n_subjects),\n",
    "    })\n",
    "\n",
    "    # Initialize second-level model with explicit parameters\n",
    "    second_level_model = SecondLevelModel(\n",
    "        smoothing_fwhm=8.0,  # Add explicit smoothing\n",
    "        n_jobs=1,  # Ensure single job for stability\n",
    "        memory=None,  # Don't cache computations\n",
    "        verbose=0  # Reduce verbosity\n",
    "    )\n",
    "\n",
    "    # Define contrasts to analyze\n",
    "    contrasts_to_analyze = [\n",
    "        'positive_vs_neutral',\n",
    "        'negative_vs_neutral',\n",
    "        'positive_vs_negative'\n",
    "    ]\n",
    "\n",
    "    # Initialize dictionary to store results\n",
    "    group_results = {}\n",
    "\n",
    "    # Process each contrast\n",
    "    for contrast_name in contrasts_to_analyze:\n",
    "        print(f\"Running group analysis for {contrast_name}...\")\n",
    "\n",
    "        # Extract and preprocess contrast maps for all subjects\n",
    "        contrast_maps_list = []\n",
    "\n",
    "        # Get the first map to use as reference\n",
    "        first_map = all_subject_contrasts[0][contrast_name]\n",
    "        reference_affine = first_map.affine\n",
    "        reference_shape = first_map.shape[:3]  # Exclude time dimension if present\n",
    "\n",
    "        # Process each subject's contrast map\n",
    "        for subject_contrasts in all_subject_contrasts:\n",
    "            contrast_img = subject_contrasts[contrast_name]\n",
    "\n",
    "            # Ensure 3D\n",
    "            if len(contrast_img.shape) == 4:\n",
    "                contrast_img = image.index_img(contrast_img, 0)\n",
    "\n",
    "            # Resample to match reference with explicit parameters\n",
    "            resampled_img = image.resample_img(\n",
    "                contrast_img,\n",
    "                target_affine=reference_affine,\n",
    "                target_shape=reference_shape,\n",
    "                interpolation='continuous',\n",
    "                force_resample=True,\n",
    "                copy_header=True,\n",
    "                clip=True\n",
    "            )\n",
    "\n",
    "            contrast_maps_list.append(resampled_img)\n",
    "\n",
    "        try:\n",
    "            # Fit the second-level model\n",
    "            second_level_model.fit(contrast_maps_list, design_matrix=design_matrix)\n",
    "\n",
    "            # Compute the group-level contrast\n",
    "            z_map = second_level_model.compute_contrast(\n",
    "                output_type='z_score',\n",
    "                second_level_stat_type='t'  # Explicitly specify t-test\n",
    "            )\n",
    "            p_map = second_level_model.compute_contrast(\n",
    "                output_type='p_value',\n",
    "                second_level_stat_type='t'\n",
    "            )\n",
    "\n",
    "            # Store results\n",
    "            group_results[contrast_name] = (z_map, p_map)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing contrast {contrast_name}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # Save group results\n",
    "    save_checkpoint(group_results, 'group_results.pkl')\n",
    "else:\n",
    "    print(\"Loaded existing group results\")"
   ],
   "id": "15e2107e117009ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running group analysis for positive_vs_neutral...\n",
      "Running group analysis for negative_vs_neutral...\n",
      "Running group analysis for positive_vs_negative...\n",
      "Checkpoint saved: fmri_project/checkpoints/group_results.pkl\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-15T10:12:00.272855Z",
     "start_time": "2025-01-15T10:11:55.668765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting parameters\n",
    "z_threshold = 3.1  # Corresponds to p < 0.001\n",
    "p_val = norm.sf(z_threshold)  # Convert Z-score to p-value\n",
    "print(f\"Z-score threshold {z_threshold} corresponds to p-value < {p_val:.3e}\")\n",
    "\n",
    "# Plot results for each contrast\n",
    "for contrast_name, (z_map, p_map) in group_results.items():\n",
    "    print(f\"Plotting results for {contrast_name}...\")\n",
    "\n",
    "    # Create figure with multiple views\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Plot sagittal, coronal, and axial views with statistical threshold\n",
    "    display = plotting.plot_stat_map(\n",
    "        z_map,\n",
    "        threshold=z_threshold,  # Apply threshold only during visualization\n",
    "        display_mode='ortho',\n",
    "        title=f'Group-level {contrast_name}\\n'\n",
    "              f'(threshold: z>{z_threshold}, p<{p_val:.3e})',\n",
    "        figure=fig\n",
    "    )\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(f'results/group_analysis_{contrast_name}(Z scores).png',\n",
    "                dpi=300,\n",
    "                bbox_inches='tight')\n",
    "    plt.close()"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-score threshold 3.1 corresponds to p-value < 9.676e-04\n",
      "Plotting results for positive_vs_neutral...\n",
      "Plotting results for negative_vs_neutral...\n",
      "Plotting results for positive_vs_negative...\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
